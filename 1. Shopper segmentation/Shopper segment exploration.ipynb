{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Spent on product categories\n",
    "2. Proportion of Changi Rewards Tier\n",
    "3. Net spend per order\n",
    "4. Frequency of purchase\n",
    "5. Recency of purchase\n",
    "6. Size of shopping cart\n",
    "7. Price sensitivity\n",
    "8. Age of shoppers\n",
    "9. Proportion of discounted transactions\n",
    "10. Proportion of subscription opt-in\n",
    "11. Gender of segment population\n",
    "12. Gross spend of subscription opt-in vs. opt-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('for_segmentation_check.csv', dtype={'CARDNO':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['ID_HASH']=1\n",
    "df = df[[df.columns[-1]] + df.columns[0:-1].tolist()]\n",
    "df.columns = ['ID_HASH', 'CARDNO', 'ORDERID', 'ISONATIONALITY', 'CREDITCARDTYPE',\n",
    "       'SALESORDERNO', 'TYPE', 'TRANSACTIONDTTM', 'TRANSACTIONDTTMKEY',\n",
    "       'GROSSAMT', 'GST', 'PROMOTIONCD', 'DISCOUNTAMT', 'NETSPEND',\n",
    "       'ARRIVALDEPARTUREIND', 'AIRPORTIATACD', 'CRREDEMPTIONAMOUNT',\n",
    "       'ORDERDETAILSID', 'PRODUCTAUTOID', 'TENANTCD', 'OUTLETID', 'OUTLETCD',\n",
    "       'UNITPRICE', 'QUANTITY', 'SUB_GROSSAMT', 'BRAND', 'CATEGORYNM',\n",
    "       'SUBCATEGORY', 'DEPARTMENT', 'PRODUCTTITLE', 'CURRENTTIERCD',\n",
    "       'MEMBERID', 'OPTIN', 'ISOCOUNTRYCD', 'JOINDATETIME', 'SIGNUPBY',\n",
    "       'SIGNUPSOURCE', 'OUTLETNM', 'PRODCODE', 'TENANTNM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(['ORDERDETAILSID', 'JOINDATETIME'], inplace=True)\n",
    "df.drop_duplicates(['ORDERDETAILSID'], inplace=True, keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['CARDNO'] = df['CARDNO'].apply(lambda x: '0000'+str(x) if len(str(x))==15 else x)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "df = df[df['TYPE']=='Sales'] #exclude refund transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['JOINDATETIME'] = df['JOINDATETIME'].astype('datetime64[ns]').dt.date\n",
    "df['TRANSACTIONDTTM'] = pd.to_datetime(df['TRANSACTIONDTTM'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['PRODCODE'] = df['PRODCODE'].replace(\n",
    "    {np.nan: 'LT',\n",
    "     'OTH': 'LT',\n",
    "     'WELLBTY': 'PC'\n",
    "    })\n",
    "\n",
    "df['PROGROUPED'] = df['PRODCODE'].apply(lambda x: 'LT' if x in ['OTH','LT']\n",
    "                                        else 'PC' if x in ['P&C','WELLBTY','PC']\n",
    "                                        else 'CCD' if x == 'CHOC/CAN/DELI'\n",
    "                                        else 'ECP' if x == 'ECP'\n",
    "                                        else 'FASHION' if x == 'MIDPRICE'\n",
    "                                        else 'PHARM' if x == 'PHARM'\n",
    "                                        else 'LUXURY' if x == 'LUX/BN'\n",
    "                                        else 'CHILDREN' if x == 'CHILDREN'\n",
    "                                        else 'OTH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "selected_columns = ['CARDNO', 'ORDERID', 'ISONATIONALITY', 'CREDITCARDTYPE',\n",
    "       'SALESORDERNO', 'TYPE', 'TRANSACTIONDTTM', 'TRANSACTIONDTTMKEY',\n",
    "       'GROSSAMT', 'GST', 'PROMOTIONCD', 'DISCOUNTAMT', 'NETSPEND',\n",
    "       'ARRIVALDEPARTUREIND', 'AIRPORTIATACD', 'CRREDEMPTIONAMOUNT',\n",
    "       'ORDERDETAILSID', 'PRODUCTAUTOID', 'TENANTCD', 'OUTLETID', 'OUTLETCD',\n",
    "       'UNITPRICE', 'QUANTITY', 'SUB_GROSSAMT', 'BRAND', 'CATEGORYNM',\n",
    "       'SUBCATEGORY', 'DEPARTMENT', 'PRODUCTTITLE', 'CURRENTTIERCD',\n",
    "       'MEMBERID', 'OPTIN', 'ISOCOUNTRYCD', 'JOINDATETIME', 'SIGNUPBY',\n",
    "       'SIGNUPSOURCE', 'OUTLETNM', 'PROGROUPED', 'TENANTNM']\n",
    "\n",
    "df_left = df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_right= pd.read_csv('segmented_new.csv', dtype={'CARDNO':str})\n",
    "\n",
    "df_supplement = pd.read_csv('supplement query 1.csv',\n",
    "                            usecols = ['ORDERDETAILSID','TENANTDISCAMT','GENDERCD'])\n",
    "df_supplement.drop_duplicates(['ORDERDETAILSID'], inplace=True, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_pre_master = df_left.merge(how = 'left', on = 'CARDNO', right = df_right)\n",
    "df_master = df_pre_master.merge(how='left', on='ORDERDETAILSID', right=df_supplement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_master = df_master.drop_duplicates()\n",
    "df_master = df_master[~df_master['CARDNO'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_down(x):\n",
    "    return math.floor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = pd.read_csv('supplement query 1.csv', usecols=['CARDNO', 'DATEOFBIRTH'],\n",
    "                    infer_datetime_format=True,\n",
    "                    dtype={'CARDNO': 'str'})\n",
    "df_age['DATEOFBIRTH'] = pd.to_datetime(df_age['DATEOFBIRTH'], format='%Y-%m-%d %H:%M:%S')\n",
    "df_age['CARDNO'] = df_age['CARDNO'].apply(lambda x: '0000' + str(x) if len(str(x)) == 15 else x)\n",
    "\n",
    "df_age.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_YEAR = datetime.strptime('2020-12-31 23:59:59', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "df_age['age_Temp'] = REF_YEAR - df_age['DATEOFBIRTH']\n",
    "df_age['age'] = (df_age['age_Temp'].dt.days / 365).apply(round_down)\n",
    "\n",
    "df_age.drop(['age_Temp'], axis=1, inplace=True)\n",
    "df_age.drop_duplicates(inplace=True)\n",
    "df_age.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Segment 0: Big-basket but low spending buyers\n",
    "- Segment 1: Alcohol lovers (with promos)\n",
    "- Segment 2: Beauty products lovers\n",
    "- Segment 3: Alcohol lovers\n",
    "- Segment 4: Big spenders\n",
    "- Segment 5: Electronics lover\n",
    "- Segment 6: Beauty products lovers (with promos)\n",
    "- Segment 7: Frequent buyers, love promo too\n",
    "- Segment 8: Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Segment 1, 2, 3, 5, 6 have very high concentration of product category. To search for cross-selling oppurunity within product category.\n",
    "- Segment 0, 4, 7, 8 to search for cross-selling oppurtunity from check-out market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seg_cat = df_master.groupby(['seg', 'PROGROUPED']).agg({'CARDNO': 'nunique'}).unstack().droplevel(0,axis=1)\n",
    "df_seg_cat['sum'] = df_seg_cat.sum(axis = 1)\n",
    "\n",
    "df_seg_cat['CCD Share'] = df_seg_cat['CCD'] / df_seg_cat['sum']\n",
    "df_seg_cat['CHILDREN Share'] = df_seg_cat['CHILDREN'] / df_seg_cat['sum']\n",
    "df_seg_cat['ECP Share'] = df_seg_cat['ECP'] / df_seg_cat['sum']\n",
    "df_seg_cat['FASHION Share'] = df_seg_cat['FASHION'] / df_seg_cat['sum']\n",
    "df_seg_cat['LT Share'] = df_seg_cat['LT'] / df_seg_cat['sum']\n",
    "df_seg_cat['LUXURY Share'] = df_seg_cat['LUXURY'] / df_seg_cat['sum']\n",
    "df_seg_cat['OTH Share'] = df_seg_cat['OTH'] / df_seg_cat['sum']\n",
    "df_seg_cat['PC Share'] = df_seg_cat['PC'] / df_seg_cat['sum']\n",
    "df_seg_cat['PHARM Share'] = df_seg_cat['PHARM'] / df_seg_cat['sum']\n",
    "\n",
    "df_seg_cat_share = df_seg_cat[['CCD Share', 'CHILDREN Share', 'ECP Share', \n",
    "                  'FASHION Share', 'LT Share', 'LUXURY Share',\n",
    "                  'OTH Share', 'PC Share', 'PHARM Share',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(df_seg_cat_share, annot = True, fmt=\".0%\", cmap=\"Blues\", ax=ax1)\n",
    "\n",
    "bottom, top= ax1.get_ylim()\n",
    "ax1.set_ylim(bottom + 0.5, top- 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CR Tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg 4 mainly made up of Gold and Platinum members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member_tier = df_master[['CARDNO', 'CURRENTTIERCD', 'seg']].drop_duplicates()\n",
    "\n",
    "df_cr_tier = df_member_tier.groupby(['seg', 'CURRENTTIERCD']).agg({\n",
    "    'CARDNO': np.count_nonzero\n",
    "}).unstack().droplevel(0, axis = 1).fillna(0)\n",
    "\n",
    "df_cr_tier = df_cr_tier[['Platinum', 'Gold', 'Member', 'Staff_Platinum', 'Staff_Gold']]\n",
    "df_cr_tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net Spend (per order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg 4 has the highest spending, by a margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_spend1 = df_master.groupby('ORDERID').agg({'NETSPEND': np.max, 'seg':np.min})\n",
    "df_net_spend2 = df_net_spend1.groupby('seg').agg({'NETSPEND': [np.count_nonzero, np.sum, np.mean]}).droplevel(0, axis = 1)\n",
    "\n",
    "df_net_spend2.sort_values('mean', ascending=False, inplace=True)\n",
    "df_net_spend2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg 7 is the only segment where all customers shopped more than once from iSC. Single spending shoppers formed 60%-80% of the remaning segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequency1 = df_master.groupby(['CARDNO']).agg({'ORDERID': 'nunique', 'seg': np.max})\n",
    "df_frequency1.columns = ['order_freq', 'seg']\n",
    "\n",
    "def less_than_10(x):\n",
    "    if x <= 9:\n",
    "        return '0' + str(x)\n",
    "    if x == 10:\n",
    "        return str(x)\n",
    "    if x > 10:\n",
    "        return '>10'\n",
    "\n",
    "df_frequency1['order_freq'] = df_frequency1['order_freq'].apply(less_than_10)\n",
    "\n",
    "df_frequency2 = df_frequency1.groupby(['seg', 'order_freq']).agg({'order_freq': np.count_nonzero}\n",
    "                                                                ).unstack().fillna(0).droplevel(0, axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequency2['sum'] = df_frequency2.sum(axis=1)\n",
    "\n",
    "df_frequency2['01_share'] = df_frequency2['01'] / df_frequency2['sum']\n",
    "df_frequency2['02_share'] = df_frequency2['02'] / df_frequency2['sum']\n",
    "df_frequency2['03_share'] = df_frequency2['03'] / df_frequency2['sum']\n",
    "df_frequency2['04_share'] = df_frequency2['04'] / df_frequency2['sum']\n",
    "df_frequency2['05_share'] = df_frequency2['05'] / df_frequency2['sum']\n",
    "df_frequency2['06_share'] = df_frequency2['06'] / df_frequency2['sum']\n",
    "df_frequency2['07_share'] = df_frequency2['07'] / df_frequency2['sum']\n",
    "df_frequency2['08_share'] = df_frequency2['08'] / df_frequency2['sum']\n",
    "df_frequency2['09_share'] = df_frequency2['09'] / df_frequency2['sum']\n",
    "df_frequency2['10_share'] = df_frequency2['10'] / df_frequency2['sum']\n",
    "df_frequency2['>10_share'] = df_frequency2['>10'] / df_frequency2['sum']\n",
    "\n",
    "\n",
    "df_frequency = df_frequency2[['01_share', '02_share', '03_share','04_share','05_share', '06_share',\n",
    "                           '07_share', '08_share', '09_share','10_share','>10_share']].T\n",
    "df_frequency.columns = ['seg ' + str(x) for x in range(0,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(5, 2, figsize=(15, 20))\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    for j in [0,1]:\n",
    "        ax[i,j].set_xticklabels(ax[0, 0].get_xticklabels(), rotation=90)\n",
    "        ax[i,j].set_ylim([0, 1])\n",
    "        \n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 0', ax=ax[0,0])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 1', ax=ax[0,1])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 2', ax=ax[1,0])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 3', ax=ax[1,1])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 4', ax=ax[2,0])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 5', ax=ax[2,1])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 6', ax=ax[3,0])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 7', ax=ax[3,1])\n",
    "sns.barplot(data=df_frequency, x=df_frequency.index, y='seg 8', ax=ax[4,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear trend on number of days apart between two transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATTERN = r'.*STAFF.*'\n",
    "promo_temp = df_master['PROMOTIONCD'].dropna()\n",
    "staff_promo_cd = promo_temp[promo_temp.str.contains(PATTERN)].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recency1 = df_master[~df_master['PROMOTIONCD'].isin(staff_promo_cd)][\n",
    "    ['CARDNO', 'ORDERID','TRANSACTIONDTTM', 'seg']].drop_duplicates(\n",
    "    ['CARDNO', 'ORDERID']).sort_values(['CARDNO', 'ORDERID']).reset_index(drop=True)\n",
    "\n",
    "df_recency1['CARDNO_SHIFT'] = df_recency1['CARDNO'].shift(-1)\n",
    "df_recency1['TRANSACTIONDTTM_SHIFT'] = df_recency1['TRANSACTIONDTTM'].shift(-1)\n",
    "df_recency1['CARDNO_SAME'] = np.where((df_recency1['CARDNO'].str[:] == df_recency1['CARDNO_SHIFT'].str[:]), 1, 0)\n",
    "\n",
    "df_recency1['time passed'] = np.where(df_recency1['CARDNO_SAME'] == 1,\n",
    "                                    (df_recency1['TRANSACTIONDTTM_SHIFT'] - df_recency1['TRANSACTIONDTTM']).dt.days,\n",
    "                                    0)\n",
    "df_recency2 = df_recency1[df_recency1['time passed'] != 0]\n",
    "#df_recency2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 2, figsize = (15,20))\n",
    "RECENCY_BINS = [x for x in range(0,200,30)]\n",
    "for i in range(len(ax)):\n",
    "    for j in [0,1]:\n",
    "        ax[i,j].set_ylim([0, 1])\n",
    "        ax[i,j].set_xticks(RECENCY_BINS)\n",
    "\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 0], x='time passed',\n",
    "             ax=ax[0,0], bins=RECENCY_BINS, hue='seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 1], x='time passed',\n",
    "             ax=ax[0,1], bins=RECENCY_BINS, hue = 'seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 2], x='time passed',\n",
    "             ax=ax[1,0], bins=RECENCY_BINS, hue = 'seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 3], x='time passed',\n",
    "             ax=ax[1,1], bins=RECENCY_BINS, hue = 'seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 4], x='time passed',\n",
    "             ax=ax[2,0], bins=RECENCY_BINS, hue = 'seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 5], x='time passed',\n",
    "             ax=ax[2,1], bins=RECENCY_BINS, hue = 'seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 6], x='time passed',\n",
    "             ax=ax[3,0], bins=RECENCY_BINS, hue = 'seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 7], x='time passed',\n",
    "             ax=ax[3,1], bins=RECENCY_BINS, hue='seg', stat='probability')\n",
    "sns.histplot(data = df_recency2[df_recency2['seg'] == 8], x='time passed',\n",
    "             ax=ax[4,0], bins=RECENCY_BINS, hue='seg', stat='probability')\n",
    "sns.histplot(data=df_recency2, x='time passed',\n",
    "             ax=ax[4,1], bins=RECENCY_BINS, stat='probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size of cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg 0 has the biggest cart per transaction, by a huge margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basket_size1 = df_master.groupby(['ORDERID']).agg({'ORDERDETAILSID': np.count_nonzero}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basket_size1.columns = ['ORDERID', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_master_reduced = df_master[['CARDNO', 'ORDERID', 'seg']].drop_duplicates(['CARDNO', 'ORDERID'])\n",
    "df_basket_size2 = df_master_reduced.merge(df_basket_size1, how='left', on='ORDERID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basket_size2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "sns.boxplot(x=\"seg\", y=\"count\", data=df_basket_size2, showfliers=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_basket_size2.groupby(['seg']).agg({'count': [stats.mode, np.mean, np.median]}).droplevel(0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No clear trend on price sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pricing = df_master[\n",
    "    ['CARDNO',\n",
    "     'QUANTITY',\n",
    "     'UNITPRICE',\n",
    "     'seg',\n",
    "     'PRODUCTTITLE',\n",
    "     'BRAND',\n",
    "     'PROGROUPED']\n",
    "]\n",
    "\n",
    "NO_OF_TOP_PROD = 5\n",
    "top_lt_products = df_master[df_master['PROGROUPED'] == 'LT'].groupby('PRODUCTTITLE').agg(\n",
    "    {'SUB_GROSSAMT': np.sum}).reset_index().sort_values(\n",
    "    'SUB_GROSSAMT', ascending = False)['PRODUCTTITLE'].head(NO_OF_TOP_PROD).tolist()\n",
    "\n",
    "df_pricing_top_prod = df_pricing.query('PRODUCTTITLE in @top_lt_products')\n",
    "\n",
    "#df_pricing_top_prod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_lt_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yamazaki = df_pricing_top_prod[df_pricing_top_prod['PRODUCTTITLE'] == 'Yamazaki 12 Years Japanese Whisky']\n",
    "\n",
    "df_mean_price = df_yamazaki.groupby(['seg', 'UNITPRICE']).agg(\n",
    "    {'UNITPRICE': np.count_nonzero}\n",
    ").unstack().droplevel(0, axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(df_mean_price,\n",
    "            annot=True,\n",
    "            fmt= \".0f\",\n",
    "            cmap=\"Blues\",\n",
    "            ax=ax1)\n",
    "\n",
    "bottom, top = ax1.get_ylim()\n",
    "ax1.set_ylim(\n",
    "    bottom + 0.5,\n",
    "    top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant in age distribution across all segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_merged = df_master[['CARDNO', 'seg']].merge(\n",
    "    df_age[['CARDNO', 'age']], how='left', on='CARDNO').drop_duplicates('CARDNO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(5,2,figsize=(20, 20))\n",
    "AGE_BINS = [x for x in range(0,100,5)]\n",
    "\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 0], x='age', ax=ax[0,0], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 1], x='age', ax=ax[0,1], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 2], x='age', ax=ax[1,0], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 3], x='age', ax=ax[1,1], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 4], x='age', ax=ax[2,0], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 5], x='age', ax=ax[2,1], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 6], x='age', ax=ax[3,0], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 7], x='age', ax=ax[3,1], bins=AGE_BINS, hue='seg')\n",
    "sns.histplot(data=df_age_merged[df_age_merged['seg'] == 8], x='age', ax=ax[4,0], bins=AGE_BINS, hue='seg')\n",
    "\n",
    "sns.histplot(data=df_age_merged, x='age', ax=ax[4,1], bins=AGE_BINS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg 6 and 7 have the highest proportion of discount over gross spend applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discount by iSC\n",
    "df_master_reduced = df_master.drop_duplicates(['ORDERID'])\n",
    "df_iSC_disc = df_master_reduced.groupby('ORDERID').agg({'DISCOUNTAMT': np.sum}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discount given by tenants\n",
    "df_tenant_disc = df_master.groupby(['ORDERID']).agg({'TENANTDISCAMT': np.sum}).reset_index()\n",
    "df_disc = df_tenant_disc.merge(right=df_iSC_disc, how ='left',on='ORDERID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disc_merged = df_disc.merge(right=df_master[['ORDERID', 'GROSSAMT', 'seg']], how='left', on='ORDERID').drop_duplicates()\n",
    "\n",
    "df_disc_merged['total_disc'] = df_disc_merged['TENANTDISCAMT'] + df_disc_merged['DISCOUNTAMT']\n",
    "df_disc_merged['disc_shares'] = df_disc_merged['total_disc'] / df_disc_merged['GROSSAMT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disc_by_seg = df_disc_merged.groupby('seg').agg({\n",
    "    'TENANTDISCAMT' : np.sum,\n",
    "    'DISCOUNTAMT': np.sum,\n",
    "    'total_disc': np.sum,\n",
    "    'GROSSAMT': np.sum\n",
    "})\n",
    "\n",
    "df_disc_by_seg['disc_share'] = df_disc_by_seg['total_disc'] / df_disc_by_seg['GROSSAMT']\n",
    "\n",
    "df_disc_by_seg.sort_values('disc_share', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seg 4 has the highest proportion of opt-in - More engaged higher spend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs = df_master.groupby(['seg', 'OPTIN']).agg({'OPTIN': np.count_nonzero}).unstack().droplevel(0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs['y_shares'] = df_subs['Y'] / df_subs.sum(axis=1)\n",
    "df_subs['n_shares'] = 1- df_subs['y_shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs.sort_values(['y_shares'], ascending=False, inplace=True)\n",
    "df_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df = df_subs.sum(axis=0).to_list()\n",
    "mean_subs = sum_df[1] / (sum_df[0] + sum_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "df_subs[['y_shares','n_shares']].plot(kind='bar',stacked=True,ax=ax)\n",
    "ax.axhline(y=mean_subs,c='r')\n",
    "\n",
    "# net spend between optin and non-optin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seg 3 has significant more male shoppers than female\n",
    "<br>seg 6 has significant more female shoppers - Logical as this seg is made up of beauty products buyers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender = df_master.groupby(['seg', 'GENDERCD']).agg({\n",
    "    'GENDERCD': np.count_nonzero\n",
    "}).unstack().droplevel(0, axis=1).drop(['U'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender['m_shares'] = df_gender['M'] / df_gender.sum(axis=1)\n",
    "df_gender['f_shares'] = 1 - df_gender['m_shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gender.sort_values(['m_shares'], ascending=False, inplace=True)\n",
    "df_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_df_gender = df_gender.sum(axis=0).to_list()\n",
    "mean_gender = sum_df_gender[1] / (sum_df_gender[0] + sum_df_gender[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "df_gender[['m_shares', 'f_shares']].plot(kind='bar', stacked=True, ax=ax)\n",
    "ax.axhline(y=mean_gender, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gross Spend by Opt In"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counter-intuiative, shoppers who opt out of newsletter subsciptions has higher per capita spend than those who opted in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_in = df_master[df_master['OPTIN'] == 'Y']\n",
    "df_opt_out = df_master[df_master['OPTIN'] == 'N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation for customers who opted in\n",
    "df_opt_in_spend1 = df_opt_in.groupby(['ORDERID']).agg({'SUB_GROSSAMT': np.sum, 'seg': np.min})\n",
    "df_opt_in_spend2 = df_opt_in_spend1.groupby('seg').agg({'SUB_GROSSAMT': np.sum}).reset_index()\n",
    "df_opt_in_spend2.columns = ['seg', 'in']\n",
    "\n",
    "df_opt_in_size = df_opt_in.groupby(['seg']).agg({'ORDERID': 'nunique'}).reset_index()\n",
    "df_opt_in_size.columns = ['seg', 'in_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation for customers who opted out\n",
    "df_opt_out_spend1 = df_opt_out.groupby(['ORDERID']).agg({'SUB_GROSSAMT': np.sum, 'seg': np.min})\n",
    "df_opt_out_spend2 = df_opt_out_spend1.groupby('seg').agg({'SUB_GROSSAMT': np.sum}).reset_index()\n",
    "df_opt_out_spend2.columns = ['seg', 'out']\n",
    "\n",
    "df_opt_out_size = df_opt_out.groupby(['seg']).agg({'ORDERID': 'nunique'}).reset_index()\n",
    "df_opt_out_size.columns = ['seg', 'out_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt_spend = df_opt_in_spend2.merge(right=df_opt_out_spend2, how='inner', on='seg')\n",
    "\n",
    "df_opt_size = df_opt_in_size.merge(right=df_opt_out_size, on='seg',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt = df_opt_spend.merge(right=df_opt_size, on='seg', how='inner')\n",
    "\n",
    "df_opt['in_per_capita'] = df_opt['in'] / df_opt['in_count']\n",
    "df_opt['out_per_capita'] = df_opt['out'] / df_opt['out_count']\n",
    "df_opt['sales difference'] = df_opt['in_per_capita'] - df_opt['out_per_capita']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_opt.sort_values('in_per_capita', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
